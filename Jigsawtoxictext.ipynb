{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport spacy\nimport string\nimport re\nimport numpy as np\nfrom spacy.symbols import ORTH\nfrom collections import Counter\nfrom pathlib import Path\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = Path(\"../input/jigsawtoxic/\")\nlist(PATH.iterdir())","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"[PosixPath('../input/jigsawtoxic/train.csv'),\n PosixPath('../input/jigsawtoxic/test.csv'),\n PosixPath('../input/jigsawtoxic/embeddings'),\n PosixPath('../input/jigsawtoxic/sample_submission.csv')]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(PATH/\"train.csv\")\ndf_test = pd.read_csv(PATH/\"test.csv\")","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train shape: \", df_train.shape)\nprint(\"Test shape: \", df_test.shape)","execution_count":6,"outputs":[{"output_type":"stream","text":"Train shape:  (1306122, 3)\nTest shape:  (375806, 2)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()\n","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"                    qid                                      question_text  \\\n0  00002165364db923c7e6  How did Quebec nationalists see their province...   \n1  000032939017120e6e44  Do you have an adopted dog, how would you enco...   \n2  0000412ca6e4628ce2cf  Why does velocity affect time? Does velocity a...   \n3  000042bf85aa498cd78e  How did Otto von Guericke used the Magdeburg h...   \n4  0000455dfa3e01eae3af  Can I convert montra helicon D to a mountain b...   \n\n   target  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00002165364db923c7e6</td>\n      <td>How did Quebec nationalists see their province...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000032939017120e6e44</td>\n      <td>Do you have an adopted dog, how would you enco...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0000412ca6e4628ce2cf</td>\n      <td>Why does velocity affect time? Does velocity a...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000042bf85aa498cd78e</td>\n      <td>How did Otto von Guericke used the Magdeburg h...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000455dfa3e01eae3af</td>\n      <td>Can I convert montra helicon D to a mountain b...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()\n","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                    qid                                      question_text\n0  0000163e3ea7c7a74cd7  Why do so many women become so rude and arroga...\n1  00002bd4fb5d505b9161  When should I apply for RV college of engineer...\n2  00007756b4a147d2b0b3  What is it really like to be a nurse practitio...\n3  000086e4b7e1c7146103                             Who are entrepreneurs?\n4  0000c4c3fbe8785a3090   Is education really making good people nowadays?","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000163e3ea7c7a74cd7</td>\n      <td>Why do so many women become so rude and arroga...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002bd4fb5d505b9161</td>\n      <td>When should I apply for RV college of engineer...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007756b4a147d2b0b3</td>\n      <td>What is it really like to be a nurse practitio...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000086e4b7e1c7146103</td>\n      <td>Who are entrepreneurs?</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000c4c3fbe8785a3090</td>\n      <td>Is education really making good people nowadays?</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.target.value_counts()\n","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"0    1225312\n1      80810\nName: target, dtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.dtypes","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"qid              object\nquestion_text    object\ntarget            int64\ndtype: object"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['question_text'] = df_train['question_text'].astype(str)\ndf_train['qid'] = df_train['qid'].astype(str)\npip install wordcloud","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud \nimport plotly.express as px\n\ndef nonan(x):\n    if type(x) == str:\n        return x.replace(\"\\n\", \"\")\n    else:\n        return \"\"\n\ntext = ' '.join([nonan(abstract) for abstract in df_train[\"question_text\"]])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text)\nfig = px.imshow(wordcloud)\nfig.update_layout(title_text='Common words in comments')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NOW WE ARE GOING TO DO Tokenization","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\ndef sub_br(x): return re_br.sub(\"\\n\", x)\n\nmy_tok = spacy.load('en')\ndef spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = df_train['question_text'][0]\nspacy_tok(text)","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"['How',\n 'did',\n 'Quebec',\n 'nationalists',\n 'see',\n 'their',\n 'province',\n 'as',\n 'a',\n 'nation',\n 'in',\n 'the',\n '1960s',\n '?']"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**NOw we are going to Compute vocab2index**"},{"metadata":{"trusted":true},"cell_type":"code","source":"counts = Counter()\nfor q in df_train['question_text']:\n    counts.update(spacy_tok(q))","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(counts.keys())\n","execution_count":15,"outputs":[{"output_type":"execute_result","execution_count":15,"data":{"text/plain":"260973"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for word in list(counts):\n    if counts[word] < 5:\n        del counts[word]","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(counts.keys())","execution_count":17,"outputs":[{"output_type":"execute_result","execution_count":17,"data":{"text/plain":"57671"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab2index = {\"\":0, \"UNK\":1}\nwords = [\"\", \"UNK\"]\nfor word in counts:\n    vocab2index[word] = len(words)\n    words.append(word)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DATASET"},{"metadata":{"trusted":true},"cell_type":"code","source":"def encode_sentence(row, vocab2index, N=100, padding_start=True):\n    words = spacy_tok(row)\n    enc = np.zeros(N, dtype=np.int32)\n    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in words])\n    l = min(N, len(enc1))\n    if padding_start:\n        enc[:l] = enc1[:l]\n    else:\n        enc[N-l:] = enc1[:l]\n    return enc, l","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encode_sentence(df_train['question_text'][0], vocab2index, N=100, padding_start=False)\n","execution_count":20,"outputs":[{"output_type":"execute_result","execution_count":20,"data":{"text/plain":"(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n         0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n       dtype=int32),\n 14)"},"metadata":{}}]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"Selection of the max sequece length N according to the 98 percentile\n","execution_count":20,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"invalid syntax (<ipython-input-20-1d802cfb1208>, line 1)","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-1d802cfb1208>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Selection of the max sequece length N according to the 98 percentile\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_len = np.array([len(q.split()) for q in df_train['question_text']])\nx_test_len = np.array([len(q.split()) for q in df_test['question_text']])","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_len.max(), x_test_len.max()\n","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(134, 87)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 99 percentile\nN_train = np.percentile(x_train_len, 99)\nN_test = np.percentile(x_test_len, 99)\n\nN_train, N_test","execution_count":23,"outputs":[{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"(39.0, 39.0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 40\n","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Split train and  valid the dataset\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train, valid = train_test_split(df_train, test_size=0.2)\n","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, valid.shape\n","execution_count":26,"outputs":[{"output_type":"execute_result","execution_count":26,"data":{"text/plain":"((1044897, 3), (261225, 3))"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Datasets(Dataset):\n    def __init__(self, df, vocab2index, is_test=False, N=40, padding_start=True):\n        self.question = [encode_sentence(q, vocab2index, N, padding_start) for q in df['question_text']]\n        self.is_test = is_test\n        if self.is_test:\n            self.y = None\n        else:\n            self.y = list(df[\"target\"])\n\n    def __len__(self):\n        return len(self.question)\n    \n    def __getitem__(self, idx):\n        x = self.question[idx]\n        if self.is_test:\n            return x\n        else:\n            y = self.y[idx]\n            return x, y","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds = Datasets(train, vocab2index, N=40, padding_start=False)\nvalid_ds = Datasets(valid, vocab2index, N=40, padding_start=False)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 1000\ntrain_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\nvalid_dl = DataLoader(valid_ds, batch_size=batch_size)","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = next(iter(train_dl))\n","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x, y = next(iter(train_dl))\nlen(x)","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"2"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"x[0].shape\n","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"torch.Size([1000, 40])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_ds[0]\n","execution_count":33,"outputs":[{"output_type":"execute_result","execution_count":33,"data":{"text/plain":"((array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n          123,   92,   19, 1217,   27, 1442,   15], dtype=int32),\n  7),\n 0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"LSTM MODEL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class LSTMModel(torch.nn.Module) :\n    def __init__(self, vocab_size, embedding_dim, hidden_dim) :\n        super(LSTMModel,self).__init__()\n        self.hidden_dim = hidden_dim\n        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)  # (batch, seq, feature)\n        self.linear = nn.Linear(hidden_dim, 1)\n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self, x):\n        x_emb = self.embeddings(x)\n        x_drop = self.dropout(x_emb)\n        out_pack, (ht, ct) = self.lstm(x_drop)\n        return self.linear(ht[-1])","execution_count":34,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_epocs(model, epochs=10, lr=0.001):\n    parameters = filter(lambda p: p.requires_grad, model.parameters())\n    optimizer = torch.optim.Adam(parameters, lr=lr)\n    for i in range(epochs):\n        model.train()\n        sum_loss = 0.0\n        total = 0\n        for x, y in train_dl:\n            x = torch.tensor(x[0], dtype=torch.long)\n            y = y.float()\n            y_pred = model(x)\n            optimizer.zero_grad()\n            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n            loss.backward()\n            optimizer.step()\n            sum_loss += loss.item()*y.shape[0]\n            total += y.shape[0]\n        val_loss, val_acc = val_metrics(model, valid_dl)\n        if i % 5 == 1:\n            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))","execution_count":35,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def val_metrics(model, valid_dl):\n    model.eval()\n    correct = 0\n    total = 0\n    sum_loss = 0.0\n    for x, y in valid_dl:\n        x = torch.tensor(x[0], dtype=torch.long)\n        y = y.float().unsqueeze(1)\n        y_hat = model(x)\n        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n        y_pred = y_hat > 0\n        correct += (y_pred.float() == y).float().sum()\n        total += y.shape[0]\n        sum_loss += loss.item()*y.shape[0]\n    return sum_loss/total, correct/total","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size = len(words)\nprint(vocab_size)\n","execution_count":37,"outputs":[{"output_type":"stream","text":"57673\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LSTMModel(vocab_size, 50, 50)\n","execution_count":38,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epocs(model, epochs=30, lr=0.01)\n","execution_count":null,"outputs":[{"output_type":"stream","text":"train loss 0.115 val loss 0.115 and val accuracy 0.956\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Making predictions by using our trained model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_ds = Datasets(df_test, vocab2index, is_test=True, N=40, padding_start=False)\ntest_dl = DataLoader(test_ds, batch_size=1000)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission = pd.read_csv(PATH/\"sample_submission.csv\")\n","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds=[]\nfor x in test_dl:\n    x = x[0].long()\n    out = model(x)\n    pred = (out > 0.0).long()\n    preds.append(pred.numpy())","execution_count":41,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission['prediction'] = np.vstack(preds)\n","execution_count":42,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.head()\n","execution_count":43,"outputs":[{"output_type":"execute_result","execution_count":43,"data":{"text/plain":"                    qid  prediction\n0  0000163e3ea7c7a74cd7           0\n1  00002bd4fb5d505b9161           1\n2  00007756b4a147d2b0b3           1\n3  000086e4b7e1c7146103           0\n4  0000c4c3fbe8785a3090           0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000163e3ea7c7a74cd7</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00002bd4fb5d505b9161</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00007756b4a147d2b0b3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>000086e4b7e1c7146103</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0000c4c3fbe8785a3090</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.to_csv('submission.csv', index=False)\n","execution_count":44,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}